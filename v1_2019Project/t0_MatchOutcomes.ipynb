{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "#from collections import defaultdict\n",
    "#from collections import Counter\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "#import os\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Purpose: get smaller-than-actual versions of each CSV, take a look at what we can get from each\n",
    "\n",
    "sourceFilePath = \"C:\\\\Users\\\\zange\\\\OneDrive\\\\Documents\\\\Business\\\\Education\\\\Drexel\\\\CS613\\\\dota-2-matches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_outcomes = pd.read_csv(open(sourceFilePath+\"\\\\match_outcomes.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ratings = pd.read_csv(open(sourceFilePath+\"\\\\player_ratings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>account_id_0</th>\n",
       "      <th>account_id_1</th>\n",
       "      <th>account_id_2</th>\n",
       "      <th>account_id_3</th>\n",
       "      <th>account_id_4</th>\n",
       "      <th>start_time</th>\n",
       "      <th>parser_version</th>\n",
       "      <th>win</th>\n",
       "      <th>rad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1636204962</td>\n",
       "      <td>34549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-51743434</td>\n",
       "      <td>-120875154</td>\n",
       "      <td>1437014585</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1636204962</td>\n",
       "      <td>0</td>\n",
       "      <td>61598</td>\n",
       "      <td>138825</td>\n",
       "      <td>0</td>\n",
       "      <td>207232</td>\n",
       "      <td>1437014585</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1636322679</td>\n",
       "      <td>0</td>\n",
       "      <td>-44943233</td>\n",
       "      <td>-240360907</td>\n",
       "      <td>19599</td>\n",
       "      <td>0</td>\n",
       "      <td>1437019968</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1636322679</td>\n",
       "      <td>-97530201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-116349387</td>\n",
       "      <td>1437019968</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1637385965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104738</td>\n",
       "      <td>0</td>\n",
       "      <td>1437052551</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     match_id  account_id_0  account_id_1  account_id_2  account_id_3  \\\n",
       "0  1636204962         34549             0             0     -51743434   \n",
       "1  1636204962             0         61598        138825             0   \n",
       "2  1636322679             0     -44943233    -240360907         19599   \n",
       "3  1636322679     -97530201             0             0             0   \n",
       "4  1637385965             0             0             0        104738   \n",
       "\n",
       "   account_id_4  start_time  parser_version  win  rad  \n",
       "0    -120875154  1437014585              12    1    0  \n",
       "1        207232  1437014585              12    0    1  \n",
       "2             0  1437019968              12    0    0  \n",
       "3    -116349387  1437019968              12    1    1  \n",
       "4             0  1437052551              12    1    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_outcomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>total_wins</th>\n",
       "      <th>total_matches</th>\n",
       "      <th>trueskill_mu</th>\n",
       "      <th>trueskill_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236579</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>27.868035</td>\n",
       "      <td>5.212361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-343</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.544163</td>\n",
       "      <td>8.065475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.521103</td>\n",
       "      <td>8.114989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.248025</td>\n",
       "      <td>8.092217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1284</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.931016</td>\n",
       "      <td>8.092224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  total_wins  total_matches  trueskill_mu  trueskill_sigma\n",
       "0      236579          14             24     27.868035         5.212361\n",
       "1        -343           1              1     26.544163         8.065475\n",
       "2       -1217           1              1     26.521103         8.114989\n",
       "3       -1227           1              1     27.248025         8.092217\n",
       "4       -1284           0              1     22.931016         8.092224"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Outcomes:  (1828588, 10)\n",
      "Radiant:  (914294, 10)\n",
      "Dire:  (914294, 10)\n"
     ]
    }
   ],
   "source": [
    "## The goal is to get each match on a single line with player accounts and their trueskill_mu and trueskill_sigma all together\n",
    "## That has several parts\n",
    "###1. break match_outcomes into two separate dataframes: one for Radiant, one for Dire\n",
    "###2. Expand each separate dataframe with the trueskill markers for each player\n",
    "###3. For each given match_id, re-stitch the two dataframes together into one frame.\n",
    "########Be very careful to correctly identify which team is Radiant AND which team won.\n",
    "radiant_mask = [rad==1 for rad in match_outcomes['rad']]\n",
    "dire_mask = [rad==0 for rad in match_outcomes['rad']]\n",
    "\n",
    "df_radiant = match_outcomes[radiant_mask]\n",
    "df_dire = match_outcomes[dire_mask]\n",
    "\n",
    "print(\"Match Outcomes: \",match_outcomes.shape)\n",
    "print(\"Radiant: \",df_radiant.shape)\n",
    "print(\"Dire: \",df_dire.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to make data more manageable, slice radiant/dire dataframes to just 50k matches\n",
    "\n",
    "df_radiant = df_radiant.head(50000)\n",
    "df_dire = df_dire.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radiant:  (50000, 10)\n",
      "Dire:  (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Radiant: \",df_radiant.shape)\n",
    "print(\"Dire: \",df_dire.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "#######Actual runtime: 45 minutes\n",
    "#######player_ratings[player_ratings['account_id']==0]\n",
    "# This is a problem. account_id==0 is a number given to players who do not allow opendota to specifically identify their account during exports.\n",
    "# For now, we will just roll with account_id==0 as if it were a person who has played 3315071 matches and take their trueskill_mu and trusekill_sigma\n",
    "# as an average for the average player with account_id==0 and see where we go from there\n",
    "\n",
    "df_radiant['ac0_trueskillmu'] = 0.0\n",
    "df_radiant['ac0_trueskillsigma'] = 0.0\n",
    "df_radiant['ac1_trueskillmu'] = 0.0\n",
    "df_radiant['ac1_trueskillsigma'] = 0.0\n",
    "df_radiant['ac2_trueskillmu'] = 0.0\n",
    "df_radiant['ac2_trueskillsigma'] = 0.0\n",
    "df_radiant['ac3_trueskillmu'] = 0.0\n",
    "df_radiant['ac3_trueskillsigma'] = 0.0\n",
    "df_radiant['ac4_trueskillmu'] = 0.0\n",
    "df_radiant['ac4_trueskillsigma'] = 0.0\n",
    "\n",
    "df_dire['ac0_trueskillmu'] = 0.0\n",
    "df_dire['ac0_trueskillsigma'] = 0.0\n",
    "df_dire['ac1_trueskillmu'] = 0.0\n",
    "df_dire['ac1_trueskillsigma'] = 0.0\n",
    "df_dire['ac2_trueskillmu'] = 0.0\n",
    "df_dire['ac2_trueskillsigma'] = 0.0\n",
    "df_dire['ac3_trueskillmu'] = 0.0\n",
    "df_dire['ac3_trueskillsigma'] = 0.0\n",
    "df_dire['ac4_trueskillmu'] = 0.0\n",
    "df_dire['ac4_trueskillsigma'] = 0.0\n",
    "\n",
    "for idx,row in df_radiant.iterrows():\n",
    "    df_radiant.at[idx,'ac0_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_0']]['trueskill_mu'])\n",
    "    df_radiant.at[idx,'ac1_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_1']]['trueskill_mu'])\n",
    "    df_radiant.at[idx,'ac2_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_2']]['trueskill_mu'])\n",
    "    df_radiant.at[idx,'ac3_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_3']]['trueskill_mu'])\n",
    "    df_radiant.at[idx,'ac4_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_4']]['trueskill_mu'])\n",
    "    df_radiant.at[idx,'ac0_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_0']]['trueskill_sigma'])\n",
    "    df_radiant.at[idx,'ac1_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_1']]['trueskill_sigma'])\n",
    "    df_radiant.at[idx,'ac2_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_2']]['trueskill_sigma'])\n",
    "    df_radiant.at[idx,'ac3_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_3']]['trueskill_sigma'])\n",
    "    df_radiant.at[idx,'ac4_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_4']]['trueskill_sigma'])\n",
    "    \n",
    "for idx,row in df_dire.iterrows():\n",
    "    df_dire.at[idx,'ac0_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_0']]['trueskill_mu'])\n",
    "    df_dire.at[idx,'ac1_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_1']]['trueskill_mu'])\n",
    "    df_dire.at[idx,'ac2_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_2']]['trueskill_mu'])\n",
    "    df_dire.at[idx,'ac3_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_3']]['trueskill_mu'])\n",
    "    df_dire.at[idx,'ac4_trueskillmu'] = float(player_ratings[player_ratings['account_id']==row['account_id_4']]['trueskill_mu'])\n",
    "    df_dire.at[idx,'ac0_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_0']]['trueskill_sigma'])\n",
    "    df_dire.at[idx,'ac1_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_1']]['trueskill_sigma'])\n",
    "    df_dire.at[idx,'ac2_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_2']]['trueskill_sigma'])\n",
    "    df_dire.at[idx,'ac3_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_3']]['trueskill_sigma'])\n",
    "    df_dire.at[idx,'ac4_trueskillsigma'] = float(player_ratings[player_ratings['account_id']==row['account_id_4']]['trueskill_sigma'])\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For backing up to save 45 minutes processing time\n",
    "df_radiant.to_csv(open(\"df_radiant_d1.csv\",\"w\"))\n",
    "df_dire.to_csv(open(\"df_dire_d1.csv\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moved to Excel to more easily remove/rename columns,ended up with the following:\n",
    "preprocessed_XandY = pd.read_csv(open(\"compiledX_noAccounts.csv\"),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'Dire_ac0_trueskillmu', 'Dire_ac0_trueskillsigma',\n",
       "       'Dire_ac1_trueskillmu', 'Dire_ac1_trueskillsigma',\n",
       "       'Dire_ac2_trueskillmu', 'Dire_ac2_trueskillsigma',\n",
       "       'Dire_ac3_trueskillmu', 'Dire_ac3_trueskillsigma',\n",
       "       'Dire_ac4_trueskillmu', 'Dire_ac4_trueskillsigma',\n",
       "       'Dire_meanTrueSkillmu', 'Dire_meanTrueSkillsigma',\n",
       "       'Radi_ac0_trueskillmu', 'Radi_ac0_trueskillsigma',\n",
       "       'Radi_ac1_trueskillmu', 'Radi_ac1_trueskillsigma',\n",
       "       'Radi_ac2_trueskillmu', 'Radi_ac2_trueskillsigma',\n",
       "       'Radi_ac3_trueskillmu', 'Radi_ac3_trueskillsigma',\n",
       "       'Radi_ac4_trueskillmu', 'Radi_ac4_trueskillsigma',\n",
       "       'Radi_meanTrueSkillmu', 'Radi_meanTrueSkillsigma', 'Radi_win'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_XandY.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Now that we have restitched everything together, it's time to figure out how best to perform this logistic regression\n",
    "### Let's pull the four features we want into a numpy array\n",
    "X = pd.DataFrame(preprocessed_XandY['Dire_meanTrueSkillmu'])\n",
    "X['Dire_meanTrueSkillsigma'] = preprocessed_XandY['Dire_meanTrueSkillsigma']\n",
    "X['Radi_meanTrueSkillmu'] = preprocessed_XandY['Radi_meanTrueSkillmu']\n",
    "X['Radi_meanTrueSkillsigma'] = preprocessed_XandY['Radi_meanTrueSkillsigma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(preprocessed_XandY['Radi_win'])\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.21466116,  6.5180607 , 24.99506614,  6.12051626],\n",
       "       [25.25767538,  6.67969932, 26.71221832,  8.06249729],\n",
       "       [25.72116133,  7.53599049, 24.59110219,  7.95222144],\n",
       "       ...,\n",
       "       [30.6747832 ,  6.34965472, 23.90165202,  7.85640872],\n",
       "       [25.80935994,  6.03820578, 26.32776747,  6.33685745],\n",
       "       [23.57007334,  4.39916558, 25.26516682,  6.42260842]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now that we have these X and Y ready to go, we can get started with the total process.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2/3 training, 1/3 testing\n",
    "trainingLen = int(np.ceil(X.shape[0]*(2/3)))\n",
    "Xtrain = X[0:trainingLen,:]\n",
    "Xtest = X[trainingLen:,:]\n",
    "Ytrain = Y[0:trainingLen,:]\n",
    "Ytest = Y[trainingLen:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainMeans = np.mean(Xtrain,axis=0)\n",
    "XtrainStds = np.std(Xtrain,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09090512, -0.00404834, -0.25794848, -0.35804378],\n",
       "       [-0.06186882,  0.12206439,  0.89897319,  1.16619501],\n",
       "       [ 0.25100254,  0.79015481, -0.53011693,  1.07964075],\n",
       "       ...,\n",
       "       [-0.46908378,  1.31506998,  1.64773502,  0.21535685],\n",
       "       [ 1.3384113 , -1.63457597,  1.12026356, -0.76113133],\n",
       "       [-0.41248459,  0.19976711, -0.82027765,  0.92366979]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainNorm = (Xtrain - XtrainMeans)*1./XtrainStds ## normalize\n",
    "XtrainNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39131924,  0.34787375,  0.95183378, -1.32514371],\n",
       "       [ 1.24738136,  0.85845012, -0.25462432,  1.37877114],\n",
       "       [-0.34258088,  1.27299944, -0.90105093, -0.15334658],\n",
       "       ...,\n",
       "       [ 3.5948934 , -0.13544105, -0.99463012,  1.00443844],\n",
       "       [ 0.3105401 , -0.3784379 ,  0.63995158, -0.18824004],\n",
       "       [-1.201067  , -1.65724013, -0.07596966, -0.12093508]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtestNorm = (Xtest - XtrainMeans)*1./XtrainStds ## normalize\n",
    "XtestNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zange\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\zange\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = logreg.score(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = logreg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rename(columns={0:'Ytest'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Output'] = p.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ytest</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ytest  Output\n",
       "0      1       1\n",
       "1      0       0\n",
       "2      0       0\n",
       "3      0       0\n",
       "4      1       0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "skprecision, skrecall, skfscore, sksupport = score(results['Ytest'],results['Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for idx,row in results.iterrows():\n",
    "    if row['Ytest']==1:\n",
    "        if row['Ytest']==row['Output']:\n",
    "            TP = TP + 1\n",
    "        else:\n",
    "            FP = FP + 1\n",
    "    else:\n",
    "        if row['Ytest']==row['Output']:\n",
    "            TN = TN + 1\n",
    "        else:\n",
    "            FN = FN + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7783865702961064\n",
      "Recall:  0.7583191368540602\n",
      "fMeasure:  0.7682218259218777\n",
      "Accuracy:  0.7582503300132005\n"
     ]
    }
   ],
   "source": [
    "precision = TP/(float(TP)+FP)\n",
    "recall = TP/(float(TP)+FN)\n",
    "fMeasure = (2*precision*recall)/(precision+recall)\n",
    "accuracy = (TP+TN)/(float(TP)+TN+FP+FN)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"Recall: \",recall)\n",
    "print(\"fMeasure: \",fMeasure)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7468350632987341"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skPrecision:  [0.75817326 0.75831914]\n",
      "skRecall:  [0.73689416 0.77838657]\n",
      "skfMeasure:  [0.74738228 0.76822183]\n",
      "skSupport:  [8088 8578]\n"
     ]
    }
   ],
   "source": [
    "print(\"skPrecision: \",skprecision)\n",
    "print(\"skRecall: \",skrecall)\n",
    "print(\"skfMeasure: \",skfscore)\n",
    "print(\"skSupport: \",sksupport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingRuns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  [[-0.70434053 -0.02324042  0.73551793  0.03208093]]\n",
      "Intercept:  [-0.83755776]\n",
      "Classes:  [0 1]\n",
      "Precision:  0.7583352762881791\n",
      "Recall:  0.7698224852071006\n",
      "fMeasure:  0.7640357058961711\n",
      "Accuracy:  0.7589103564142565\n"
     ]
    }
   ],
   "source": [
    "### running the regression with multiple testing samples\n",
    "allTols = [.0001]\n",
    "for inputTol in allTols:\n",
    "    logreg = sklearn.linear_model.LogisticRegression(penalty='l2',dual=False,tol=inputTol, \\\n",
    "                                                     C=1.0,fit_intercept=True,intercept_scaling=1, \\\n",
    "                                                     class_weight='balanced',random_state=0, \\\n",
    "                                                     solver='liblinear',max_iter=100,multi_class='ovr', \\\n",
    "                                                     verbose=0,warm_start=False,n_jobs=None)\n",
    "    logreg.fit(Xtrain,np.ravel(Ytrain))\n",
    "    sc = logreg.score(Xtrain,np.ravel(Ytrain))\n",
    "    p = logreg.predict(Xtest)\n",
    "    results = pd.DataFrame(Ytest)\n",
    "    results.rename(columns={0:'Ytest'},inplace=True)\n",
    "    results['Output'] = p.T\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for idx,row in results.iterrows():\n",
    "        if row['Ytest']==1:\n",
    "            if row['Ytest']==row['Output']:\n",
    "                TP = TP + 1\n",
    "            else:\n",
    "                FP = FP + 1\n",
    "        else:\n",
    "            if row['Ytest']==row['Output']:\n",
    "                TN = TN + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "    \n",
    "    precision = TP/(float(TP)+FP)\n",
    "    recall = TP/(float(TP)+FN)\n",
    "    fMeasure = (2*precision*recall)/(precision+recall)\n",
    "    accuracy = (TP+TN)/(float(TP)+TN+FP+FN)\n",
    "    print(\"Coefficient: \",logreg.coef_)\n",
    "    print(\"Intercept: \", logreg.intercept_)\n",
    "    print(\"Classes: \",logreg.classes_)\n",
    "    print(\"Precision: \",precision)\n",
    "    print(\"Recall: \",recall)\n",
    "    print(\"fMeasure: \",fMeasure)\n",
    "    print(\"Accuracy: \",accuracy)\n",
    "    testingRuns.append((logreg,(precision,recall,fMeasure,accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
